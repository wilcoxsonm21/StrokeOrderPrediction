{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "urGngiqE4VTe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from IPython.display import Image as im, display\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from psutil import cpu_count\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl18mREF5nmH",
        "outputId": "142fe35c-dac2-4286-d80b-8b542fc4b319"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvG8OX4yasYB",
        "outputId": "96fadf53-38b3-474f-8b7e-49b4dc701d79"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir /root/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle/kaggle.json /root/.kaggle/\n",
        "! chmod 600 /root/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d maxwilcoxson/hanzi-writer-dataset-png\n",
        "! unzip hanzi-writer-dataset-png.zip\n",
        "! rm hanzi-writer-dataset-png.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AYizsMuZ4VTh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.RandomResizedCrop(size=(256, 256), scale=(0.8, 1), ratio=(3/4, 4/3))\n",
        "\n",
        "#transforms a list ofimages with a rotating crop, and returns the original and rotated images\n",
        "def transformImages(original):\n",
        "    images = []\n",
        "    for i in range(len(original)):\n",
        "        images.append(transforms.functional.pil_to_tensor(original[i]))\n",
        "    images = torch.stack(images)\n",
        "    images = images.squeeze(1)\n",
        "    t1 = transform(images).numpy()\n",
        "    t1im = []\n",
        "    for i in range(len(t1)):\n",
        "        t1im.append(Image.fromarray(t1[i]))\n",
        "    return {\"or\": original, \"t1\": t1im}\n",
        "\n",
        "#loads and transforms subset of images into a numpy array, resizing for 140x140\n",
        "#to compose inputs and 28x28 images to be arranged to make grid for outputs\n",
        "def loadImages(start, end):\n",
        "    path = \"/content/data/\"\n",
        "    inputs = {}\n",
        "    outputs = {}\n",
        "    for character in os.listdir(path)[start:end]:\n",
        "        if not character.startswith(\".\"):\n",
        "            images = []\n",
        "            for filename in sorted(os.listdir(path + character), key=lambda x: int(x.split(\".\")[0][1:])):\n",
        "                if filename.endswith(\".png\"):\n",
        "                    original = Image.open(path + character + \"/\" + filename).convert(\"L\")\n",
        "                    images.append(original)\n",
        "        versions = transformImages(images)\n",
        "        for k, imgSet in versions.items():\n",
        "            full_size = []\n",
        "            small_size = []\n",
        "            for img in imgSet:\n",
        "                full_size.append(np.array(img.resize((140,140))))\n",
        "                small_size.append(np.array(img.resize((28,28))))\n",
        "            currentSmall = 255.0*((np.array(small_size)/255.0)**3) #cube normalized pixel values to increase contrast\n",
        "            currentLarge = 255.0*((np.array(full_size)/255.0)**3)\n",
        "            inputs[k + \"-\" + character] = currentLarge\n",
        "            outputs[k + \"-\" + character] = currentSmall\n",
        "    return inputs, outputs\n",
        "\n",
        "#for a given set of 25x25 images, concatenates them into a 5x5 grid\n",
        "#pads unused entries with zeroes, and returns the resulting 140x140 numpy array\n",
        "def concatentatePartsIntoGrid(images):\n",
        "    newArray = 255*np.ones((140, 140))\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            if i*5 + j >= len(images):\n",
        "                break\n",
        "            newArray[i*28:(i+1)*28, j*28:(j+1)*28] = images[i*5+j]\n",
        "    return newArray\n",
        "\n",
        "#to check the input processing, given an array of 140x140 numpy arrays, this function\n",
        "#saves each array as an image and returns the list of names for the saved images\n",
        "def saveImages(images, t):\n",
        "    names = []\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        img = Image.fromarray(image)\n",
        "        img = img.convert('RGB')\n",
        "        if not os.path.exists(\"/content/outputtest\"):\n",
        "            os.mkdir(\"/content/outputtest\")\n",
        "        outputfile = \"/content/outputtest/\" + str(i) + t + \".png\"\n",
        "        with(open(outputfile, \"w\")) as f:\n",
        "            f.write(\"\")\n",
        "        f.close()\n",
        "        img.save(outputfile)\n",
        "        names.append(outputfile)\n",
        "    return names\n",
        "\n",
        "#augments the dataset by taking every prefix of the n strokes required to write\n",
        "#each character, and creates a new datapoint from this prefix, with the k stroke\n",
        "# prefix of the character and sequence of the first k strokes in a grid\n",
        "def augmentDataset(full, small):\n",
        "    Y_aug = []\n",
        "    X_aug = []\n",
        "    for character in full:\n",
        "        full_images = full[character]\n",
        "        small_images = small[character]\n",
        "        for i in range(1, len(full_images)+1):\n",
        "            Y_aug.append(concatentatePartsIntoGrid(small_images[:i]))\n",
        "            X_aug.append(full_images[i-1])\n",
        "    return np.array(X_aug), np.array(Y_aug)\n",
        "\n",
        "#given a list of 140x140 arrays, returns a dictionary where the 140x140 arrays\n",
        "#have been sliced into 25 28x28 arrays (these will be individual elements fed to transformer)\n",
        "def sliceImages(images, key):\n",
        "    inputs = {}\n",
        "    for index in range(images.shape[0]):\n",
        "        inputs[str(index) + \"-\" + key] = np.array([images[index][i:i+28, j:j+28].flatten() for i in range(0, 140, 28) for j in range(0, 140, 28)])\n",
        "        inputs[str(index) + \"-\" + key] = (inputs[str(index) + \"-\" + key]/255.0) - 0.5 #center data around 0, range of about 1\n",
        "    return inputs\n",
        "\n",
        "#returns the processed, augmented X input images, output images Y, and filesX and filesY for\n",
        "#images from start to end\n",
        "def getDataSubset(start, end):\n",
        "    X, Y = loadImages(start, end)\n",
        "    X, Y = augmentDataset(X, Y)\n",
        "    data = list(zip(X,Y))\n",
        "    random.shuffle(data)\n",
        "    X, Y = zip(*data)\n",
        "    X, Y = np.array(X), np.array(Y)\n",
        "    filesY = saveImages(Y, \"Y\")\n",
        "    filesX = saveImages(X, \"X\")\n",
        "    X = sliceImages(X, str(start) + \"-\" + str(end))\n",
        "    Y = sliceImages(Y, str(start) + \"-\" + str(end))\n",
        "    return X, Y, filesX, filesY\n",
        "\n",
        "#computes a 75-25 split of the training and validation data\n",
        "def testTrainSplit(X, Y):\n",
        "    k_t = list(X.keys())[:int(len(X)*0.75)]\n",
        "    k_v = list(X.keys())[int(len(X)*0.75):]\n",
        "    X_t = {}\n",
        "    Y_t = {}\n",
        "    X_v = {}\n",
        "    Y_v = {}\n",
        "    for k in k_t:\n",
        "        X_t[k] = X[k]\n",
        "        Y_t[k] = Y[k]\n",
        "    for k in k_v:\n",
        "        X_v[k] = X[k]\n",
        "        Y_v[k] = Y[k]\n",
        "    return X_t, X_v, Y_t, Y_v\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UJbq01n0LiXH",
        "outputId": "0cb30e24-d77d-44bd-96c7-f24e34f552ee"
      },
      "outputs": [],
      "source": [
        "#loads the data and displays some smaples\n",
        "X, Y, filesX, filesY = getDataSubset(0,4000)\n",
        "\n",
        "X, X_test, Y, Y_test = testTrainSplit(X, Y)\n",
        "\n",
        "for fx, fy in zip(filesX[:20], filesY[:20]):\n",
        "    display(im(filename=fx))\n",
        "    display(im(filename=fy))\n",
        "print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cNCUjNRKh2c3"
      },
      "outputs": [],
      "source": [
        "#some utility functions to save preprocessed input to persistent disk\n",
        "import pickle\n",
        "import shutil\n",
        "def save_variable_to_disk(var, filename):\n",
        "    dest_folder = '/content/drive/MyDrive/' + filename\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(var, f)\n",
        "    shutil.move(filename, dest_folder)\n",
        "def load_variable_from_disk(filename):\n",
        "    filename = '/content/drive/MyDrive/' + filename\n",
        "    with open(filename, 'rb') as f:\n",
        "      return pickle.load(f)\n",
        "def saveDictionaries(X, Y, Xv, Yv, pre):\n",
        "    save_variable_to_disk(X, pre + 'X.pkl')\n",
        "    save_variable_to_disk(Y, pre + 'Y.pkl')\n",
        "    save_variable_to_disk(Xv, pre + 'Xv.pkl')\n",
        "    save_variable_to_disk(Yv, pre + 'Yv.pkl')\n",
        "def loadDictionaries(pre):\n",
        "    X = load_variable_from_disk(pre + 'X.pkl')\n",
        "    Y = load_variable_from_disk(pre + 'Y.pkl')\n",
        "    Xv = load_variable_from_disk(pre + 'Xv.pkl')\n",
        "    Yv = load_variable_from_disk(pre + 'Yv.pkl')\n",
        "    return X, Y, Xv, Yv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cKRFw2kSgDS8"
      },
      "outputs": [],
      "source": [
        "X, Y, X_test, Y_test = loadDictionaries(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lctRDszO4VTi"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# PositionalEncoding class is from https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "#trainable linear projection, scaled by sqrt d\n",
        "class Projection(nn.Module):\n",
        "    def __init__(self, n, d, device):\n",
        "        super(Projection, self).__init__()\n",
        "        self.d = d\n",
        "        self.linearProjection = nn.Linear(n, d).to(device)\n",
        "    def forward(self, x):\n",
        "        return math.sqrt(self.d)*self.linearProjection(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ArYQnPO84VTi"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, n, d, num_heads, num_en_layers, num_dec_layers, output_size, device):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.projection = Projection(n, d, device).to(device)\n",
        "        self.position = PositionalEncoding(d)\n",
        "        self.transformer = nn.Transformer(d_model=d,\n",
        "                                          nhead=num_heads, num_encoder_layers=num_en_layers,\n",
        "                                          num_decoder_layers=num_dec_layers, dim_feedforward=2048,dropout=0.0).to(device)\n",
        "        self.out = nn.Linear(d, output_size).to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "\n",
        "        src = self.projection(src)\n",
        "        src = src + self.position(src)\n",
        "        #need to reshape, batch size must be second dimension, not first for transfomer\n",
        "        src = src.reshape(src.shape[0], -1, src.shape[-1])\n",
        "        tgt = self.projection(tgt)\n",
        "        tgt = tgt + self.position(tgt)\n",
        "        tgt = tgt.reshape(tgt.shape[0], -1, tgt.shape[-1])\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "        transformer_output = self.transformer(src, tgt, tgt_mask=nn.Transformer.generate_square_subsequent_mask(tgt.shape[0]).to(self.device))\n",
        "        return self.out(transformer_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CnmelF204VTj"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Transformer(784, 256, 8, 4, 4, 784, device).to(device) \n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=3000)\n",
        "loss_fn = nn.MSELoss()\n",
        "#xavier uniform initialization\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p, gain=nn.init.calculate_gain('relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jCqbFJaR4VTj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#converts dictionary of 140x140 numpy arrays to a tensor\n",
        "def convertToTensors(inputs):\n",
        "    result = []\n",
        "    for character in inputs:\n",
        "        result.append(torch.from_numpy(inputs[character]).to(torch.float32))\n",
        "    return torch.stack(result)\n",
        "X = convertToTensors(X).to(device)\n",
        "Y = convertToTensors(Y).to(device)\n",
        "X_test = convertToTensors(X_test).to(device)\n",
        "Y_test = convertToTensors(Y_test).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Z1ZjyHDp4VTk"
      },
      "outputs": [],
      "source": [
        "#adds 28x28 block of all -1 as a start token (not a possible value)\n",
        "def addStartTokens(inputs, device):\n",
        "    result = []\n",
        "    for i in range(inputs.shape[0]):\n",
        "        result.append(torch.cat((torch.ones((1,784)).to(device)*-1, inputs[i]), dim=0))\n",
        "    return torch.stack(result).to(device)\n",
        "\n",
        "#adds 28x28 block of all 1 as a start token (not a possible value)\n",
        "def addEndTokens(outputs, device):\n",
        "    result = []\n",
        "    for i in range(outputs.shape[0]):\n",
        "        result.append(torch.cat((outputs[i], torch.ones((1,784)).to(device)*1), dim=0))\n",
        "    return torch.stack(result).to(device)\n",
        "\n",
        "#repeatedly calls the model to predict one token at a time\n",
        "#have garbage for Y_part other than start token to demonstrate that mask is working\n",
        "def inference(X_part):\n",
        "    Y_part = 1000*torch.ones(X_part.shape[0], 25, X_part.shape[2]).to(device)\n",
        "    X_part = addEndTokens(X_part, device)\n",
        "    Y_part = addStartTokens(Y_part, device)\n",
        "    for i in range(1,27):\n",
        "        Y_part = model(X_part, Y_part)\n",
        "        Y_part = Y_part.permute(1,0,2)\n",
        "        if i < 26:\n",
        "            Y_part = torch.roll(Y_part, 1, 1)\n",
        "            Y_part[:,0,:] = -1\n",
        "    return Y_part\n",
        "\n",
        "#given an array of images, displays them\n",
        "#kind variable controls what the names map to\n",
        "def showImages(images, kind):\n",
        "    images = images.reshape(images.shape[0], images.shape[1], 28, 28)\n",
        "    gridImages = []\n",
        "    for i in range(images.shape[0]):\n",
        "      gridImages.append(concatentatePartsIntoGrid(255.0*(images[i] + 0.5)))\n",
        "    files = saveImages(gridImages, kind)\n",
        "    for f in files:\n",
        "        display(im(filename=f))\n",
        "\n",
        "#calculates the loss for a subset of the dataset, and shows a few of the images\n",
        "def calculateLoss(X, Y, kind, epoch):\n",
        "    with torch.no_grad():\n",
        "      batch_size = 32\n",
        "      l = 0\n",
        "      for i in range(0, 128, batch_size):\n",
        "          X_part = X[i:i+batch_size]\n",
        "          Y_part = Y[i:i+batch_size]\n",
        "          Y_exp = addEndTokens(Y_part, device)\n",
        "          Y_act = inference(X_part)\n",
        "          l += loss_fn(Y_act ,Y_exp)\n",
        "          if i + batch_size >= batch_size:\n",
        "              showImages(Y_act[:1].cpu().detach().numpy(), kind)\n",
        "              showImages(Y_exp[:1].cpu().detach().numpy(), kind)\n",
        "              showImages(X_part[:1].cpu().detach().numpy(), kind)\n",
        "      print(\"the \" + kind + \" loss is \" + str(l) + \" at epoch \" + str(epoch))\n",
        "    return l / int(len(X)/batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DXWYBtGPZ8Yu",
        "outputId": "7d7b6ad7-6032-4604-be62-fa3be498a918"
      },
      "outputs": [],
      "source": [
        "n_epochs=3000\n",
        "batch_size = 32\n",
        "losses_train = []\n",
        "losses_valid = []\n",
        "for e in range(n_epochs):\n",
        "    indices = list(range(0, len(X), batch_size))\n",
        "    random.shuffle(indices) #very important! don't forget randomization\n",
        "    print(indices)\n",
        "    for i in indices:\n",
        "        X_part = X[i:i+batch_size]\n",
        "        X_part = addEndTokens(X_part, device)\n",
        "        Y_part = Y[i:i+batch_size]\n",
        "        Y_part_tgt = addStartTokens(Y_part, device)\n",
        "        Y_part_exp = addEndTokens(Y_part, device)\n",
        "        Y_part_pred = model(X_part, Y_part_tgt)\n",
        "        Y_part_pred = Y_part_pred.permute(1,0,2)\n",
        "        loss = loss_fn(Y_part_pred, Y_part_exp) #ignore end token\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    if e % 10 == 0:\n",
        "        showImages(Y_part_exp[3:4].cpu().detach().numpy(), \"train\")\n",
        "        showImages(Y_part_pred[3:4].cpu().detach().numpy(), \"train\")\n",
        "        showImages(X_part[3:4].cpu().detach().numpy(), \"train\")\n",
        "        losses_train.append(calculateLoss(X, Y, \"train\", e))\n",
        "        losses_valid.append(calculateLoss(X_test, Y_test, \"valid\", e))\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/transformeraugmented' + str(e) + '.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "DPzdmgjt8ItV",
        "outputId": "6caf7baa-acf8-4790-e205-68f403cac8f8"
      },
      "outputs": [],
      "source": [
        "# plots the training and validation loss over time\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(torch.stack(losses_train).cpu().detach().numpy(), label='Training Loss', color='blue')\n",
        "plt.plot(torch.stack(losses_valid).cpu().detach().numpy(), label='Validation Loss', color='red')\n",
        "plt.title('Training vs Validation Loss Over Time')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "D3i0Qd6qObt-"
      },
      "outputs": [],
      "source": [
        "def calculateTotalLoss(X, Y, kind):\n",
        "    with torch.no_grad():\n",
        "      batch_size = 32\n",
        "      l = 0\n",
        "      indices = list(range(0, len(X), batch_size))\n",
        "      random.shuffle(indices)\n",
        "      for i in indices:\n",
        "          X_part = X[i:i+batch_size]\n",
        "          Y_part = Y[i:i+batch_size]\n",
        "          Y_exp = addEndTokens(Y_part, device)\n",
        "          Y_act = inference(X_part)\n",
        "          l += loss_fn(Y_act ,Y_exp)\n",
        "          if random.random() < 0.05:\n",
        "              showImages(Y_act[:1].cpu().detach().numpy(), kind)\n",
        "              showImages(Y_exp[:1].cpu().detach().numpy(), kind)\n",
        "              showImages(X_part[:1].cpu().detach().numpy(), kind)\n",
        "    return l / int(len(X)/batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Geez1kgRkMSX",
        "outputId": "19dd63e1-0c20-43a2-f48b-8eb5886f827b"
      },
      "outputs": [],
      "source": [
        "# loads many models and computes train and validation loss for each model\n",
        "losses_train = []\n",
        "losses_valid = []\n",
        "def loadModels():\n",
        "    for n in range(10, 830, 10):\n",
        "        print(n)\n",
        "        model.load_state_dict(torch.load(\"/content/drive/MyDrive/transformer\" + str(n) + \".pth\"))\n",
        "        model.eval()\n",
        "        losses_train.append(calculateTotalLoss(X, Y, \"train\", n))\n",
        "        losses_valid.append(calculateTotalLoss(X_test, Y_test, \"valid\", n))\n",
        "    return\n",
        "loadModels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icV5Xd5Qs3NM",
        "outputId": "88bd587c-c5e6-41be-dbed-bdbc46a935eb"
      },
      "outputs": [],
      "source": [
        "# loads test data\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/transformeraugmented690.pth\"))\n",
        "model.eval()\n",
        "X_extratest, Y_extratest, filesX, filesY = getDataSubset(4000,5000)\n",
        "X_extratest = convertToTensors(X_extratest).to(device)\n",
        "Y_extratest = convertToTensors(Y_extratest).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W0SOW4c6avIY",
        "outputId": "7f669700-77b2-4efa-e956-035ff2b0ef71"
      },
      "outputs": [],
      "source": [
        "# calculates loss on test and visualizes a few data points\n",
        "calculateLoss(X_extratest, Y_extratest, \"valid\", 0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
